## Copyright (C) 2010, Paco Nathan. This work is licensed under 
## the BSD License. To view a copy of this license, visit:
##    http://creativecommons.org/licenses/BSD/
## or send a letter to:
##    Creative Commons, 171 Second Street, Suite 300
##    San Francisco, California, 94105, USA
##
## @author Paco Nathan <ceteri@gmail.com>


Slinky provides high-performance Web Crawler and Text Analytics 
implemented in Python.

  * uses Redis key/value store for both URI Queue and Page Store
  * uses Hadoop, R, Gephi for Text Analytics and Link Analytics


Requires:
	http://github.com/andymccurdy/redis-py
	http://www.crummy.com/software/BeautifulSoup/

Usage:
	# initialize the URI Queue and Page Store
	./src/slinky.py redis_host:port:db flush
	./src/slinky.py redis_host:port:db config < config.tsv
	./src/slinky.py redis_host:port:db seed < urls.tsv
	./src/slinky.py redis_host:port:db whitelist < whitelist.tsv

	# perform a crawl, per worker node
	./src/slinky.py redis_host:port:db crawl

	# pull the Hadoop mapper input for Text Analytics
	./src/slinky.py redis_host:port:db textkeys
